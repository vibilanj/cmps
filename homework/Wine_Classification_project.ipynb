{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Wine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the necessary imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "CF_red = (204/255, 121/255, 167/255)\n",
    "CF_vermillion = (213/255, 94/255, 0)\n",
    "CF_orange = (230/255, 159/255, 0)\n",
    "CF_yellow = (240/255, 228/255, 66/255)\n",
    "CF_green = (0, 158/255, 115/255)\n",
    "CF_sky = (86/255, 180/255, 233/255)\n",
    "CF_blue = (0, 114/255, 178/255)\n",
    "CF_black = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As you might know, some fancy people have standards when it comes to wine. They insist that not all fermented grape juice is equal. In this project, we will try to predict whether a wine will be \"good\" or not based on a number of measurements.\n",
    "\n",
    "Let us start by downloading the relevant datasets: one for red wine and another for white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two URL's for the datasets:\n",
    "url_red_wine = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "url_white_wine = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "# Load the dataset by reading the CSV into a data structure. Notice the \"sep\" parameter in the function.\n",
    "# Why is it there?\n",
    "\n",
    "red_wine_data = pd.read_csv(url_red_wine, sep = ';');\n",
    "white_wine_data = pd.read_csv(url_white_wine, sep = ';');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Now that the data is loaded, show the first 10 entries in each of the two datasets. Remeber, when we use *pandas* to read the data, the output is a dataframe which has all kinds of convenient functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  \n",
       "5      9.4        5  \n",
       "6      9.4        5  \n",
       "7     10.0        7  \n",
       "8      9.5        7  \n",
       "9     10.5        5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "5            8.1              0.28         0.40             6.9      0.050   \n",
       "6            6.2              0.32         0.16             7.0      0.045   \n",
       "7            7.0              0.27         0.36            20.7      0.045   \n",
       "8            6.3              0.30         0.34             1.6      0.049   \n",
       "9            8.1              0.22         0.43             1.5      0.044   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "5                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "6                 30.0                 136.0   0.9949  3.18       0.47   \n",
       "7                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "8                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "9                 28.0                 129.0   0.9938  3.22       0.45   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  \n",
       "5     10.1        6  \n",
       "6      9.6        6  \n",
       "7      8.8        6  \n",
       "8      9.5        6  \n",
       "9     11.0        6  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first 10 entries in both datasets using the `head` method. There are 12 columns in each dataset containing numerical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the data sets has samples of wine with corresponding measurements and a \"quality\" label ranging from 1 to 10.\n",
    "\n",
    "### Question 2:\n",
    "\n",
    "For each of the datasets, show the count for each quality score. Think of a good way of presenting it so the reader can quickly see how the scores are distributed. *Hint: You need to look only at the quality column for each dataset and find out how many times each number shows up.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7e706ffb74f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_counts = red_wine_data.groupby(\"quality\").size()\n",
    "red_counts = pd.concat([red_counts, pd.Series([0], index=[9])]) \n",
    "white_counts = white_wine_data.groupby(\"quality\").size()\n",
    "\n",
    "labels = red_counts.index\n",
    "w = 0.4\n",
    "hw = w / 2\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.bar(labels - hw, red_counts, width = w, color = CF_red, label = \"Red Wine\")\n",
    "ax.bar(labels + hw, white_counts, width = w, color = CF_blue, label = \"White Wine\")\n",
    "ax.set(xlabel = \"Quality Score\", ylabel = \"Count\", title = \"Counts for Wine Quality Score\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can present the count of each quality score as a bar graph. This will allow us to quickly see how the scores are distributed. We can also combine the two datasets into one and show the count of each quality score for both red and white wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to be able to classify our wines as \"good\" (quality 7 or above) or \"not\" (otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Add a column to both datasets that labels the wine as good or not. Remember, later on we will want to use this label in our neural networks so think of how to make it computationally friendly.\n",
    "*Hint: Take a look here https://stackoverflow.com/questions/26886653/pandas-create-new-column-based-on-values-from-other-columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_data[\"good quality\"] = red_wine_data.apply(lambda x: x[\"quality\"] >= 7, axis=1)\n",
    "white_wine_data[\"good quality\"] = white_wine_data.apply(lambda x: x[\"quality\"] >= 7, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can easily add the new label column using the `apply` method and a `lambda` function to check if the quality is greater than or equal to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "The next step is to create the training and the test sets. Here, we will use 75% of the datasets for training and the remaining portion for testing.\n",
    "\n",
    "#### (a)\n",
    "\n",
    "We don't know whether the items in the table are arranged in any way. Shuffle them. *Hint: search 'pandas shuffle'. Look at the stackoverflow result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_data = red_wine_data.sample(frac = 1).reset_index(drop = True)\n",
    "white_wine_data = white_wine_data.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Take 75% of the datasets to create the training sets. Use the remaining data for the test sets. *Hint: look at how we did this for the Iris dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amount_red = int(0.75 * len(red_wine_data))\n",
    "train_red_wine = red_wine_data.head(train_amount_red)\n",
    "test_red_wine = red_wine_data.tail(len(red_wine_data) - train_amount_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amount_white = int(0.75 * len(white_wine_data))\n",
    "train_white_wine = white_wine_data.head(train_amount_white)\n",
    "test_white_wine = white_wine_data.tail(len(white_wine_data) - train_amount_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can shuffle the data using the `sample` method and then split the data into training and test sets using the `head` and `tail` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "For all the dataseta, create the \"measurements\" sets and the corresponding labels. You should have 8 items in total: measurements + labels for training and testing for two wine types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_red_wine_measurements = train_red_wine.drop([\"quality\", \"good quality\"], axis = 1).values\n",
    "train_red_wine_labels = train_red_wine[\"good quality\"]\n",
    "\n",
    "test_red_wine_measurements = test_red_wine.drop([\"quality\", \"good quality\"], axis = 1).values\n",
    "test_red_wine_labels = test_red_wine[\"good quality\"]\n",
    "\n",
    "train_white_wine_measurements = train_white_wine.drop([\"quality\", \"good quality\"], axis = 1).values\n",
    "train_white_wine_labels = train_white_wine[\"good quality\"]\n",
    "\n",
    "test_white_wine_measurements = test_white_wine.drop([\"quality\", \"good quality\"], axis = 1).values\n",
    "test_white_wine_labels = test_white_wine[\"good quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the measurements sets we can use the `drop` method to remove the \"quality\" and \"good quality\" columns. We can then get the labels by simply selecting the \"good quality\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Create and compile two models using keras: one for red wine, another for white. The architecture is up to you. What is the smallest network you need to get decent results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation = \"sigmoid\"),\n",
    "    keras.layers.Dense(2, activation = \"softmax\") \n",
    "])\n",
    "\n",
    "white_wine_model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation = \"sigmoid\"),\n",
    "    keras.layers.Dense(2, activation = \"softmax\") \n",
    "])\n",
    "\n",
    "red_wine_model.compile(optimizer = 'adam',\n",
    "                       loss = 'sparse_categorical_crossentropy',\n",
    "                       metrics = ['accuracy'])\n",
    "\n",
    "white_wine_model.compile(optimizer = 'adam',\n",
    "                         loss = 'sparse_categorical_crossentropy',\n",
    "                         metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the two models using the `Sequential` class and add a few layers to each model. We can use the `Dense` class to add fully connected layers. \n",
    "The first layer uses the `Sigmoid` activation function and the second layer uses the `Softmax` activation function. We can compile the model using the `compile` method and specify the loss function and optimizer. We use the \"accuracy\" metric to evaluate the model.\n",
    "\n",
    "The smallest size for the first layer that provided good results was 8. Additionally, the last layer contains two nodes since our predictions have two classes (good and not good)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7:\n",
    "\n",
    "Train the models. How well to they perform on the training and test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 971us/step - loss: 0.4663 - accuracy: 0.8574\n",
      "Epoch 2/3\n",
      "38/38 [==============================] - 0s 959us/step - loss: 0.4323 - accuracy: 0.8574\n",
      "Epoch 3/3\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.4167 - accuracy: 0.8574\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8850\n",
      "Epoch 1/3\n",
      "115/115 [==============================] - 0s 969us/step - loss: 0.6594 - accuracy: 0.6169\n",
      "Epoch 2/3\n",
      "115/115 [==============================] - 0s 963us/step - loss: 0.5280 - accuracy: 0.7830\n",
      "Epoch 3/3\n",
      "115/115 [==============================] - 0s 973us/step - loss: 0.5248 - accuracy: 0.7830\n",
      "39/39 [==============================] - 0s 889us/step - loss: 0.5219 - accuracy: 0.7853\n",
      "Red Wine Test accuracy: 0.8849999904632568\n",
      "White Wine Test accuracy: 0.7853060960769653\n"
     ]
    }
   ],
   "source": [
    "red_wine_model.fit(train_red_wine_measurements, train_red_wine_labels, epochs = 3)\n",
    "red_test_loss, red_test_acc = red_wine_model.evaluate(test_red_wine_measurements, test_red_wine_labels)\n",
    "\n",
    "white_wine_model.fit(train_white_wine_measurements, train_white_wine_labels, epochs = 3)\n",
    "white_test_loss, white_test_acc = white_wine_model.evaluate(test_white_wine_measurements, test_white_wine_labels)\n",
    "\n",
    "print('Red Wine Test accuracy:', red_test_acc)\n",
    "print('White Wine Test accuracy:', white_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the models using the `fit` method and provide the training data and labels and the number of epochs. We can then evaluate the models using the `evaluate` method on the test data and labels. We see that the red wine model has an accuracy or 88% and the white wine model has an accuracy of 79% on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Question 8:\n",
    "\n",
    "How do you know you are not overfitting/underfitting\n",
    "Explain why over/underfitting would be a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we are not overfitting because the accuracy on the test data is similar to the accuracy on the training data. If the accuracy on the test data was much lower than the accuracy on the training data, then we would be overfitting. \n",
    "\n",
    "Overfitting is a problem because this means that the model would not generalize well to new data. On the other hand, underfitting means that our model has not been able to capture the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9:\n",
    "\n",
    "Accuracy does not give the full picture. Analyze your predictions based on other evaluation metrics: **precision** and **recall**. Compare and contrast the two metrics. What do their scores tell you about your model results and how it can be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 868us/step\n",
      "39/39 [==============================] - 0s 791us/step\n",
      "Red Wine Precision: 0.7832250000000001, Recall: 0.885\n",
      "White Wine Precision: 0.6167057059558517, Recall: 0.7853061224489796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibilanj/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vibilanj/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "red_test_predictions = np.argmax(red_wine_model.predict(test_red_wine_measurements), axis=-1)\n",
    "red_precision = precision_score(test_red_wine_labels, red_test_predictions, average='weighted')\n",
    "red_recall = recall_score(test_red_wine_labels, red_test_predictions, average='weighted')\n",
    "\n",
    "white_test_predictions = np.argmax(white_wine_model.predict(test_white_wine_measurements), axis=-1)\n",
    "white_precision = precision_score(test_white_wine_labels, white_test_predictions, average='weighted')\n",
    "white_recall = recall_score(test_white_wine_labels, white_test_predictions, average='weighted')\n",
    "\n",
    "print(f\"Red Wine Precision: {red_precision}, Recall: {red_recall}\")\n",
    "print(f\"White Wine Precision: {white_precision}, Recall: {white_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall metrics give us a better idea of how well our model is performing. Precision measures the proportion of predicted positive cases that are actually positive. It answers the question: \"Of all the items we predicted as positive, how many are actually positive?\" In this example, it measures how many of the wines we predicted as \"good\" are actually \"good\". Recall measures the proportion of actual positive cases that we correctly identified by the model. It answers the question: \"Of all the actual positive cases, how many did we correctly identify?\" In this example, it measueres how many of the actual \"good\" wines we correctly identified as \"good\".\n",
    "\n",
    "For both red wine and white wine models, the recall was higher than the precision. This means that it is better at correctly identifying positive instances (i.e., true positives) among all the actual positive instances in the dataset. However, it may also be identifying some negative instances as positive (i.e., false positives), which lowers the precision. So, the model is good at identifying \"good\" wines but might be incorrectly identifying some \"not good\" wines as \"good\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10:\n",
    "\n",
    "How do you think you precision and recall results would change based on the proportional breakdown between \"good\" and \"bad\" wines in your datasets? How would you solve the problem of an imbalanced dataset? *Hint: imagine your dataset only has good/bad wines and your model becomes great at predicting only one category. Google \"imbalanced datasets\".* \n",
    "\n",
    "**You do not need to implement the different scenarios or the fix. Simply provide a discussion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall results would change based on the proportional breakdown between \"good\" and \"bad\" wines in the datasets. If the dataset has more \"good\" wines than \"bad\" wines, then the model would be better at predicting \"good\" wines. This would result in a higher recall and lower precision. On the other hand, if the dataset has more \"bad\" wines than \"good\" wines, then the model would be better at predicting \"bad\" wines. This would result in a higher precision and lower recall.\n",
    "\n",
    "A way we could solve this problem is by picking a subset of the data that has an equal number of \"good\" and \"bad\" wines for training. This would ensure that the model is not biased towards one class. These techniques are known as resampling methods and include oversampling and undersampling. Oversampling involves increasing the number of instances in the minority class, while undersampling involves decreasing the number of instances in the majority class. Another technique is to use a different evaluation metric that is robust to imbalanced datasets, such as the F1 score or the area under the ROC curve. These metrics take into account both precision and recall and provide a more balanced view of the model's performance."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
