{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Wine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the necessary imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As you might know, some fancy people have standards when it comes to wine. They insist that not all fermented grape juice is equal. In this project, we will try to predict whether a wine will be \"good\" or not based on a number of measurements.\n",
    "\n",
    "Let us start by downloading the relevant datasets: one for red wine and another for white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two URL's for the datasets:\n",
    "url_red_wine = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "url_white_wine = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "# Load the dataset by reading the CSV into a data structure. Notice the \"sep\" parameter in the function.\n",
    "# Why is it there?\n",
    "\n",
    "red_wine_data = pd.read_csv(url_red_wine, sep = ';');\n",
    "white_wine_data = pd.read_csv(url_white_wine, sep = ';');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Now that the data is loaded, show the first 10 entries in each of the two datasets. Remeber, when we use *pandas* to read the data, the output is a dataframe which has all kinds of convenient functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the data sets has samples of wine with corresponding measurements and a \"quality\" label ranging from 1 to 10.\n",
    "\n",
    "### Question 2:\n",
    "\n",
    "For each of the datasets, show the count for each quality score. Think of a good way of presenting it so the reader can quickly see how the scores are distributed. *Hint: You need to look only at the quality column for each dataset and find out how many times each number shows up.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to be able to classify our wines as \"good\" (quality 7 or above) or \"not\" (otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Add a column to both datasets that labels the wine as good or not. Remember, later on we will want to use this label in our neural networks so think of how to make it computationally friendly.\n",
    "*Hint: Take a look here https://stackoverflow.com/questions/26886653/pandas-create-new-column-based-on-values-from-other-columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "The next step is to create the training and the test sets. Here, we will use 75% of the datasets for training and the remaining portion for testing.\n",
    "\n",
    "#### (a)\n",
    "\n",
    "We don't know whether the items in the table are arranged in any way. Shuffle them. *Hint: search 'pandas shuffle'. Look at the stackoverflow result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Take 75% of the datasets to create the training sets. Use the remaining data for the test sets. *Hint: look at how we did this for the Iris dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "For all the dataseta, create the \"measurements\" sets and the corresponding labels. You should have 8 items in total: measurements + labels for training and testing for two wine types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Create and compile two models using keras: one for red wine, another for white. The architecture is up to you. What is the smallest network you need to get decent results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7:\n",
    "\n",
    "Train the models. How well to they perform on the training and test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Question 8:\n",
    "\n",
    "How do you know you are not overfitting/underfitting\n",
    "Explain why over/underfitting would be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9:\n",
    "\n",
    "Accuracy does not give the full picture. Analyze your predictions based on other evaluation metrics: **precision** and **recall**. Compare and contrast the two metrics. What do their scores tell you about your model results and how it can be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10:\n",
    "\n",
    "How do you think you precision and recall results would change based on the proportional breakdown between \"good\" and \"bad\" wines in your datasets? How would you solve the problem of an imbalanced dataset? *Hint: imagine your dataset only has good/bad wines and your model becomes great at predicting only one category. Google \"imbalanced datasets\".* \n",
    "\n",
    "**You do not need to implement the different scenarios or the fix. Simply provide a discussion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
